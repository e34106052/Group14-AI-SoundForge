import flet as ft
import os
import random



def get_interaction_screen(page, genre_dropdown, length_dropdown,
                           audio_player_interaction, audio_player_result,
                           progress_bar, generated_text,
                           sample_playlist, optimized_prompts, duration_dict,
                           music_save_path, last_genre, last_length,
                           result_info,
                           last_generated_path,
                           switch_to):


    # ä½¿ç”¨è€…ä¸‹æ‹‰é¸æ“‡æƒ³è¦é è¦½çš„é¢¨æ ¼
    sample_genre_dropdown = ft.Dropdown(
        label="Sample Genre",
        options=[ft.dropdown.Option(g) for g in os.listdir("sample")
                 if os.path.isdir(os.path.join("sample", g)) and not g.startswith(".")],
        width=300
    )

    # æ’­æ”¾ sample éŸ³æ¨‚çš„å‡½å¼
    def load_sample_music(e):
        genre = sample_genre_dropdown.value
        if not genre:
            return

        genre_path = os.path.join("sample", genre)
        sample_files = [f for f in os.listdir(genre_path) if f.endswith(".wav")]
        
        if not sample_files:
            return
            
        selected_file = random.choice(sample_files)
        full_path = os.path.join(genre_path, selected_file)
                
        # æ›´æ–° Playlist
        sample_playlist.controls.clear()
        sample_playlist.controls.append(
            ft.ListTile(
                leading=ft.Icon(ft.icons.MUSIC_NOTE),
                title=ft.Text(f"{genre} - {selected_file}"),
                on_click=lambda e, f=full_path: play_sample(f)
            )
        )
        sample_playlist.update()

    #æ’­æ”¾æŒ‰éˆ•ä½¿ç”¨çš„æ’­æ”¾å‡½å¼
    def play_sample(filepath):
        audio_player_interaction.src = filepath
        audio_player_interaction.update()

    
    def generate_music(e):
        genre = genre_dropdown.value
        length_sec = length_dropdown.value
        last_genre["value"] = genre
        last_length["value"] = length_sec

        audio_player_interaction.pause()# åœæ­¢ interaction çš„éŸ³æ¨‚æ’­æ”¾

        if not genre or not length_sec:
            generated_text.value = "âš ï¸ Please select music genre and length!"
            page.update()
            return

        save_dir = music_save_path["value"] or "C:\\AI_SoundForge"
        os.makedirs(save_dir, exist_ok=True)

        progress_bar.visible = True
        generated_text.value = "ğŸ¶ Generating music, please wait..."
        page.update()

        from music_gen.generate import generate_and_predict
        prompt = optimized_prompts[genre]
        duration_tokens = duration_dict[length_sec]
        filename = f"{genre.lower()}.wav"
        result = generate_and_predict(prompt, filename, duration_tokens, save_dir=save_dir)

        progress_bar.visible = False

        if result["predicted_genre"]:

            # å„²å­˜éŸ³æ¨‚æª”æ¡ˆè·¯å¾‘ï¼Œå‚³çµ¦ result ç•«é¢
            last_generated_path["value"] = result["filename"]
            # è¨­å®š audio_player_result æ’­æ”¾
            audio_player_result.src = result["filename"]
            audio_player_result.update()

            # è¨˜éŒ„ metadata
            filename = result["filename"]
            predicted_genre = result["predicted_genre"]

            result_info["value"] = (
                f"âœ… Music generation completed!\n"
                f"ğŸ“‚ Saved as: {filename}\n"
                f"ğŸ¯ Requested Genre: {genre}\n"
                f"ğŸ” Predicted Genre: {predicted_genre}"
            )
            
            # è‡ªå‹•åˆ‡æ›ç•«é¢åˆ° Result
            switch_to("result")

        else:
            generated_text.value = f"âŒ Something wrong, please try againï¼š{result.get('error')}"
            page.update()

    def go_back(e):
        switch_to("initial")

    interaction_screen = ft.Column(
        [
            ft.Row(
                [
                    #é é¢æ¨™é¡Œå’Œè¿”å›éµ
                    ft.Text("ğŸ¼ Music Generator", size=24, weight="bold"),
                    ft.IconButton(ft.icons.ARROW_BACK, on_click=go_back),
                ],
                alignment=ft.MainAxisAlignment.SPACE_BETWEEN
            ),
            ft.Row([
                    #å·¦å´ï¼šè©¦è½sample
                    ft.Column([
                        ft.Text("ğŸ§ Preview Sample Tracks"),
                        sample_genre_dropdown,
                        ft.ElevatedButton("Load Sample", on_click=load_sample_music),
                        ft.Container(
                            sample_playlist,
                            height=120,  # é™åˆ¶ playlist é«˜åº¦
                            bgcolor=ft.colors.GREY_100,
                            border_radius=10,
                            padding=5
                        ),
                        ft.Container(
                            audio_player_interaction,
                            height=40  # æ§åˆ¶ audio player é«˜åº¦
                        ),
                        ft.Row([
                            ft.ElevatedButton("â–¶ï¸ Play", on_click=lambda e: audio_player_interaction.play()),
                            ft.ElevatedButton("â¸ Pause", on_click=lambda e: audio_player_interaction.pause()),
                        ], alignment=ft.MainAxisAlignment.CENTER)
                    ], expand=1),

                    # å³å´ï¼šç”Ÿæˆ
                    ft.Column([
                        ft.Text("ğŸ¶ Generate Music"),
                        ft.Text("Select the music style you like!"),
                        genre_dropdown,
                        ft.Text("Select the music length you prefer!"),
                        length_dropdown,
                        ft.ElevatedButton("Generate Music", icon=ft.icons.MUSIC_NOTE, on_click=generate_music),
                        ft.Container(progress_bar, height=10),
                        ft.Container(generated_text, bgcolor="lightgrey", height=100)
                    ], expand=1)
            ],
            alignment=ft.MainAxisAlignment.START,
            spacing=30
        )
        ])

    return interaction_screen
